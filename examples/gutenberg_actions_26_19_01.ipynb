{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "# Apply the patch to allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "from dotenv import load_dotenv\n",
    "from minference.threads.inference import InferenceOrchestrator, RequestLimits\n",
    "from minference.threads.models import ChatMessage, ChatThread, LLMConfig, CallableTool, LLMClient,ResponseFormat, SystemPrompt, StructuredTool, Usage,GeneratedJsonObject\n",
    "from typing import Literal, List\n",
    "from minference.ecs.caregistry import CallableRegistry\n",
    "import time\n",
    "from minference.clients.utils import msg_dict_to_oai, msg_dict_to_anthropic, parse_json_string\n",
    "from minference.ecs.entity import EntityRegistry\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "EntityRegistry()\n",
    "CallableRegistry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_request_limits = RequestLimits(max_requests_per_minute=10000, max_tokens_per_minute=200000000)\n",
    "# lite_llm_request_limits = RequestLimits(max_requests_per_minute=500, max_tokens_per_minute=200000)\n",
    "anthropic_request_limits = RequestLimits(max_requests_per_minute=500, max_tokens_per_minute=80000)\n",
    "vllm_request_limits = RequestLimits(max_requests_per_minute=100, max_tokens_per_minute=200000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_model = \"claude-3-5-sonnet-latest\"\n",
    "vllm_model = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "openai_model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator = InferenceOrchestrator(oai_request_limits=oai_request_limits, vllm_request_limits=vllm_request_limits)\n",
    "EntityRegistry.set_inference_orchestrator(orchestrator)\n",
    "EntityRegistry.set_tracing_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_string = \"\"\"# Narrative Action Extraction System\n",
    "\n",
    "You are an expert system designed to extract structured actions from narrative text. Your primary goal is to identify and extract concrete physical interactions, movements, and observable behaviors from narratives, even when they might be subtle or implied. Always prioritize finding actions rather than concluding none exist.\n",
    "\n",
    "## IMPORTANT: Action Extraction Is Your Primary Task\n",
    "\n",
    "The most important part of your analysis is extracting actions between entities. **ALWAYS thoroughly search for actions in the text before concluding none exist.** Consider these types of interactions as valid actions:\n",
    "\n",
    "1. Direct physical interactions (e.g., \"Maya picked up the lantern\")\n",
    "2. Movements (e.g., \"The fox darted into the forest\")\n",
    "3. Observable behaviors (e.g., \"Professor Lin frowned\", \"Raj smiled\")\n",
    "4. Implied physical actions (e.g., \"Sarah found herself tumbling down the hillside\" implies the action \"tumble\")\n",
    "5. Actions described in dialogue (e.g., \"'I tossed it over the fence,' said Eliza\" implies the action \"toss\")\n",
    "\n",
    "**Do not be overly strict in what qualifies as an action.** If there is any observable behavior or physical movement in the text, it should be captured as an action.\n",
    "\n",
    "## Action Extraction Process\n",
    "\n",
    "1. **First, carefully read the text and list all potential actions** - be generous in what you consider an action\n",
    "2. Identify all entity names involved in these actions\n",
    "3. Determine entity types and which entities are characters\n",
    "4. Record different mentions of each entity\n",
    "5. Identify locations where actions take place\n",
    "6. For each potential action:\n",
    "   - Identify source entity (who/what performs the action)\n",
    "   - Identify target entity (who/what receives the action)\n",
    "   - Extract the verb describing the action\n",
    "   - Determine the consequence of the action\n",
    "   - Note text evidence supporting the action\n",
    "   - Assign a location and temporal order\n",
    "\n",
    "## NarrativeAnalysis Model Structure\n",
    "\n",
    "The NarrativeAnalysis model contains:\n",
    "- `text_id`: A unique identifier for the analyzed text segment\n",
    "- `text_had_no_actions`: Boolean indicating whether the text contained actions (default to FALSE)\n",
    "- `text_had_no_actions_explanation`: Optional explanation if no actions were found\n",
    "- `entity_names`: List of all distinct entity names in the text\n",
    "- `entity_types`: Dictionary mapping entity names to their types\n",
    "- `character_entities`: List of entity names that are characters\n",
    "- `entity_mentions`: Dictionary mapping entity names to their textual mentions\n",
    "- `locations`: List of hierarchical location paths\n",
    "- `location_descriptions`: Dictionary mapping location paths to descriptions\n",
    "- `action_names`: List of all action names extracted (THIS IS IMPORTANT!)\n",
    "- `actions`: Dictionary mapping action names to Action objects\n",
    "\n",
    "## Expanded Definition of Valid Actions\n",
    "\n",
    "An action is valid if it meets the following criteria:\n",
    "- It involves an observable behavior, movement, or interaction\n",
    "- The source entity can be identified (who/what performs the action)\n",
    "- There is some effect or consequence of the action\n",
    "- It occurs in a narrative context (actual or implied location)\n",
    "\n",
    "For subtle or implied actions:\n",
    "- If a character speaks, \"speak\" is a valid action\n",
    "- If a character shows emotion (smiles, frowns, etc.), that is a valid action\n",
    "- If a character appears, disappears, or changes state, that is a valid action\n",
    "- If a character observes something, \"observe\" is a valid action\n",
    "\n",
    "## Example Narrative Analysis\n",
    "\n",
    "For the text: \n",
    "\"Maya entered the dimly lit cave in the coastal cliffs. Her flashlight revealed ancient symbols carved into the stone walls. She ran her fingers over the rough surface, feeling the grooves of the markings. A sudden noise startled her, and she spun around, dropping her notebook on the damp ground. From the shadows, a small fox emerged, its eyes reflecting the light. Maya smiled at the creature before carefully picking up her notebook.\"\n",
    "\n",
    "The NarrativeAnalysis would look like:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"text_id\": \"maya-cave-exploration\",\n",
    "  \"text_had_no_actions\": false,\n",
    "  \"entity_names\": [\"Maya\", \"cave\", \"flashlight\", \"symbols\", \"stone walls\", \"fingers\", \"noise\", \"notebook\", \"fox\", \"eyes\"],\n",
    "  \"entity_types\": {\n",
    "    \"Maya\": \"person\",\n",
    "    \"cave\": \"location\",\n",
    "    \"flashlight\": \"object\",\n",
    "    \"symbols\": \"object\",\n",
    "    \"stone walls\": \"object\",\n",
    "    \"fingers\": \"object\",\n",
    "    \"noise\": \"object\",\n",
    "    \"notebook\": \"object\",\n",
    "    \"fox\": \"animal\",\n",
    "    \"eyes\": \"object\"\n",
    "  },\n",
    "  \"character_entities\": [\"Maya\", \"fox\"],\n",
    "  \"entity_mentions\": {\n",
    "    \"Maya\": [\"Maya\", \"her\", \"she\"],\n",
    "    \"cave\": [\"cave\"],\n",
    "    \"flashlight\": [\"flashlight\"],\n",
    "    \"symbols\": [\"symbols\", \"markings\"],\n",
    "    \"stone walls\": [\"stone walls\"],\n",
    "    \"fingers\": [\"fingers\"],\n",
    "    \"noise\": [\"noise\"],\n",
    "    \"notebook\": [\"notebook\"],\n",
    "    \"fox\": [\"fox\", \"creature\"],\n",
    "    \"eyes\": [\"eyes\"]\n",
    "  },\n",
    "  \"locations\": [\n",
    "    [\"coastal cliffs\", \"cave\"]\n",
    "  ],\n",
    "  \"location_descriptions\": {\n",
    "    \"coastal cliffs->cave\": \"A dimly lit cave in the coastal cliffs with ancient symbols carved into stone walls\"\n",
    "  },\n",
    "  \"action_names\": [\"enter\", \"reveal\", \"run\", \"feel\", \"startle\", \"spin\", \"drop\", \"emerge\", \"reflect\", \"smile\", \"pick up\"],\n",
    "  \"actions\": {\n",
    "    \"enter\": {\n",
    "      \"source\": \"Maya\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"cave\",\n",
    "      \"target_type\": \"location\",\n",
    "      \"target_is_character\": false,\n",
    "      \"action\": \"enter\",\n",
    "      \"consequence\": \"Maya is now inside the cave\",\n",
    "      \"text_describing_the_action\": \"Maya entered the dimly lit cave in the coastal cliffs\",\n",
    "      \"text_describing_the_consequence\": \"Maya is inside the dimly lit cave\",\n",
    "      \"location\": [\"coastal cliffs\", \"cave\"],\n",
    "      \"temporal_order_id\": 1\n",
    "    },\n",
    "    \"reveal\": {\n",
    "      \"source\": \"flashlight\",\n",
    "      \"source_type\": \"object\",\n",
    "      \"source_is_character\": false,\n",
    "      \"target\": \"symbols\",\n",
    "      \"target_type\": \"object\",\n",
    "      \"target_is_character\": false,\n",
    "      \"action\": \"reveal\",\n",
    "      \"consequence\": \"The ancient symbols become visible\",\n",
    "      \"text_describing_the_action\": \"Her flashlight revealed ancient symbols carved into the stone walls\",\n",
    "      \"text_describing_the_consequence\": \"The ancient symbols are now visible to Maya\",\n",
    "      \"location\": [\"coastal cliffs\", \"cave\"],\n",
    "      \"temporal_order_id\": 2\n",
    "    },\n",
    "    \"run\": {\n",
    "      \"source\": \"Maya\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"symbols\",\n",
    "      \"target_type\": \"object\",\n",
    "      \"target_is_character\": false,\n",
    "      \"action\": \"run\",\n",
    "      \"consequence\": \"Maya's fingers trace over the symbols\",\n",
    "      \"text_describing_the_action\": \"She ran her fingers over the rough surface\",\n",
    "      \"text_describing_the_consequence\": \"Maya's fingers are in contact with the symbols\",\n",
    "      \"location\": [\"coastal cliffs\", \"cave\"],\n",
    "      \"temporal_order_id\": 3\n",
    "    },\n",
    "    \"feel\": {\n",
    "      \"source\": \"Maya\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"symbols\",\n",
    "      \"target_type\": \"object\",\n",
    "      \"target_is_character\": false,\n",
    "      \"action\": \"feel\",\n",
    "      \"consequence\": \"Maya senses the texture of the symbols\",\n",
    "      \"text_describing_the_action\": \"feeling the grooves of the markings\",\n",
    "      \"text_describing_the_consequence\": \"Maya has tactile information about the symbols\",\n",
    "      \"location\": [\"coastal cliffs\", \"cave\"],\n",
    "      \"temporal_order_id\": 4\n",
    "    },\n",
    "    \"startle\": {\n",
    "      \"source\": \"noise\",\n",
    "      \"source_type\": \"object\",\n",
    "      \"source_is_character\": false,\n",
    "      \"target\": \"Maya\",\n",
    "      \"target_type\": \"person\",\n",
    "      \"target_is_character\": true,\n",
    "      \"action\": \"startle\",\n",
    "      \"consequence\": \"Maya is frightened\",\n",
    "      \"text_describing_the_action\": \"A sudden noise startled her\",\n",
    "      \"text_describing_the_consequence\": \"Maya becomes afraid due to the noise\",\n",
    "      \"location\": [\"coastal cliffs\", \"cave\"],\n",
    "      \"temporal_order_id\": 5\n",
    "    },\n",
    "    \"spin\": {\n",
    "      \"source\": \"Maya\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"cave\",\n",
    "      \"target_type\": \"location\",\n",
    "      \"target_is_character\": false,\n",
    "      \"action\": \"spin\",\n",
    "      \"consequence\": \"Maya changes direction to face the noise\",\n",
    "      \"text_describing_the_action\": \"she spun around\",\n",
    "      \"text_describing_the_consequence\": \"Maya is now facing a different direction\",\n",
    "      \"location\": [\"coastal cliffs\", \"cave\"],\n",
    "      \"temporal_order_id\": 6\n",
    "    },\n",
    "    \"drop\": {\n",
    "      \"source\": \"Maya\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"notebook\",\n",
    "      \"target_type\": \"object\",\n",
    "      \"target_is_character\": false,\n",
    "      \"action\": \"drop\",\n",
    "      \"consequence\": \"The notebook falls to the ground\",\n",
    "      \"text_describing_the_action\": \"dropping her notebook on the damp ground\",\n",
    "      \"text_describing_the_consequence\": \"The notebook is now on the ground\",\n",
    "      \"location\": [\"coastal cliffs\", \"cave\"],\n",
    "      \"temporal_order_id\": 7\n",
    "    },\n",
    "    \"emerge\": {\n",
    "      \"source\": \"fox\",\n",
    "      \"source_type\": \"animal\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"cave\",\n",
    "      \"target_type\": \"location\",\n",
    "      \"target_is_character\": false,\n",
    "      \"action\": \"emerge\",\n",
    "      \"consequence\": \"The fox becomes visible\",\n",
    "      \"text_describing_the_action\": \"From the shadows, a small fox emerged\",\n",
    "      \"text_describing_the_consequence\": \"The fox is now visible in the cave\",\n",
    "      \"location\": [\"coastal cliffs\", \"cave\"],\n",
    "      \"temporal_order_id\": 8\n",
    "    },\n",
    "    \"reflect\": {\n",
    "      \"source\": \"eyes\",\n",
    "      \"source_type\": \"object\",\n",
    "      \"source_is_character\": false,\n",
    "      \"target\": \"light\",\n",
    "      \"target_type\": \"object\",\n",
    "      \"target_is_character\": false,\n",
    "      \"action\": \"reflect\",\n",
    "      \"consequence\": \"The fox's eyes shine\",\n",
    "      \"text_describing_the_action\": \"its eyes reflecting the light\",\n",
    "      \"text_describing_the_consequence\": \"The fox's eyes are gleaming\",\n",
    "      \"location\": [\"coastal cliffs\", \"cave\"],\n",
    "      \"temporal_order_id\": 9\n",
    "    },\n",
    "    \"smile\": {\n",
    "      \"source\": \"Maya\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"fox\",\n",
    "      \"target_type\": \"animal\",\n",
    "      \"target_is_character\": true,\n",
    "      \"action\": \"smile\",\n",
    "      \"consequence\": \"Maya expresses a positive emotion toward the fox\",\n",
    "      \"text_describing_the_action\": \"Maya smiled at the creature\",\n",
    "      \"text_describing_the_consequence\": \"Maya shows friendliness toward the fox\",\n",
    "      \"location\": [\"coastal cliffs\", \"cave\"],\n",
    "      \"temporal_order_id\": 10\n",
    "    },\n",
    "    \"pick up\": {\n",
    "      \"source\": \"Maya\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"notebook\",\n",
    "      \"target_type\": \"object\",\n",
    "      \"target_is_character\": false,\n",
    "      \"action\": \"pick up\",\n",
    "      \"consequence\": \"Maya retrieves her notebook from the ground\",\n",
    "      \"text_describing_the_action\": \"carefully picking up her notebook\",\n",
    "      \"text_describing_the_consequence\": \"The notebook is now in Maya's possession again\",\n",
    "      \"location\": [\"coastal cliffs\", \"cave\"],\n",
    "      \"temporal_order_id\": 11\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "## Example With Dialogue and Subtle Actions\n",
    "\n",
    "For the text:\n",
    "\"Professor Lin sat quietly at her desk, lost in thought. The window was open, and a gentle breeze rustled the papers. She glanced at the clock and sighed. 'I need to finish these reports before the meeting,' she whispered to herself. As she reached for her pen, her colleague Raj appeared at the doorway. 'Working late again?' he asked with a concerned expression. Professor Lin nodded slightly without looking up.\"\n",
    "\n",
    "The NarrativeAnalysis would look like:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"text_id\": \"professor-lin-office\",\n",
    "  \"text_had_no_actions\": false,\n",
    "  \"entity_names\": [\"Professor Lin\", \"desk\", \"window\", \"breeze\", \"papers\", \"clock\", \"reports\", \"pen\", \"Raj\", \"doorway\"],\n",
    "  \"entity_types\": {\n",
    "    \"Professor Lin\": \"person\",\n",
    "    \"desk\": \"object\",\n",
    "    \"window\": \"object\",\n",
    "    \"breeze\": \"object\",\n",
    "    \"papers\": \"object\",\n",
    "    \"clock\": \"object\",\n",
    "    \"reports\": \"object\",\n",
    "    \"pen\": \"object\",\n",
    "    \"Raj\": \"person\",\n",
    "    \"doorway\": \"location\"\n",
    "  },\n",
    "  \"character_entities\": [\"Professor Lin\", \"Raj\"],\n",
    "  \"entity_mentions\": {\n",
    "    \"Professor Lin\": [\"Professor Lin\", \"her\", \"she\", \"herself\"],\n",
    "    \"desk\": [\"desk\"],\n",
    "    \"window\": [\"window\"],\n",
    "    \"breeze\": [\"breeze\"],\n",
    "    \"papers\": [\"papers\"],\n",
    "    \"clock\": [\"clock\"],\n",
    "    \"reports\": [\"reports\"],\n",
    "    \"pen\": [\"pen\"],\n",
    "    \"Raj\": [\"Raj\", \"colleague\", \"he\"],\n",
    "    \"doorway\": [\"doorway\"]\n",
    "  },\n",
    "  \"locations\": [\n",
    "    [\"office\", \"desk\"]\n",
    "  ],\n",
    "  \"location_descriptions\": {\n",
    "    \"office->desk\": \"Professor Lin's office where she works at her desk\"\n",
    "  },\n",
    "  \"action_names\": [\"sit\", \"rustle\", \"glance\", \"sigh\", \"whisper\", \"reach\", \"appear\", \"ask\", \"nod\"],\n",
    "  \"actions\": {\n",
    "    \"sit\": {\n",
    "      \"source\": \"Professor Lin\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"desk\",\n",
    "      \"target_type\": \"object\",\n",
    "      \"target_is_character\": false,\n",
    "      \"action\": \"sit\",\n",
    "      \"consequence\": \"Professor Lin is positioned at her desk\",\n",
    "      \"text_describing_the_action\": \"Professor Lin sat quietly at her desk\",\n",
    "      \"text_describing_the_consequence\": \"Professor Lin is seated at her desk\",\n",
    "      \"location\": [\"office\", \"desk\"],\n",
    "      \"temporal_order_id\": 1\n",
    "    },\n",
    "    \"rustle\": {\n",
    "      \"source\": \"breeze\",\n",
    "      \"source_type\": \"object\",\n",
    "      \"source_is_character\": false,\n",
    "      \"target\": \"papers\",\n",
    "      \"target_type\": \"object\",\n",
    "      \"target_is_character\": false,\n",
    "      \"action\": \"rustle\",\n",
    "      \"consequence\": \"The papers move slightly\",\n",
    "      \"text_describing_the_action\": \"a gentle breeze rustled the papers\",\n",
    "      \"text_describing_the_consequence\": \"The papers are moving due to the breeze\",\n",
    "      \"location\": [\"office\", \"desk\"],\n",
    "      \"temporal_order_id\": 2\n",
    "    },\n",
    "    \"glance\": {\n",
    "      \"source\": \"Professor Lin\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"clock\",\n",
    "      \"target_type\": \"object\",\n",
    "      \"target_is_character\": false,\n",
    "      \"action\": \"glance\",\n",
    "      \"consequence\": \"Professor Lin observes the time\",\n",
    "      \"text_describing_the_action\": \"She glanced at the clock\",\n",
    "      \"text_describing_the_consequence\": \"Professor Lin is aware of the time\",\n",
    "      \"location\": [\"office\", \"desk\"],\n",
    "      \"temporal_order_id\": 3\n",
    "    },\n",
    "    \"sigh\": {\n",
    "      \"source\": \"Professor Lin\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"Professor Lin\",\n",
    "      \"target_type\": \"person\",\n",
    "      \"target_is_character\": true,\n",
    "      \"action\": \"sigh\",\n",
    "      \"consequence\": \"Professor Lin expresses weariness\",\n",
    "      \"text_describing_the_action\": \"and sighed\",\n",
    "      \"text_describing_the_consequence\": \"Professor Lin shows fatigue or resignation\",\n",
    "      \"location\": [\"office\", \"desk\"],\n",
    "      \"temporal_order_id\": 4\n",
    "    },\n",
    "    \"whisper\": {\n",
    "      \"source\": \"Professor Lin\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"Professor Lin\",\n",
    "      \"target_type\": \"person\",\n",
    "      \"target_is_character\": true,\n",
    "      \"action\": \"whisper\",\n",
    "      \"consequence\": \"Professor Lin verbalizes her thoughts\",\n",
    "      \"text_describing_the_action\": \"she whispered to herself\",\n",
    "      \"text_describing_the_consequence\": \"Professor Lin has voiced her concern about finishing reports\",\n",
    "      \"location\": [\"office\", \"desk\"],\n",
    "      \"temporal_order_id\": 5\n",
    "    },\n",
    "    \"reach\": {\n",
    "      \"source\": \"Professor Lin\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"pen\",\n",
    "      \"target_type\": \"object\",\n",
    "      \"target_is_character\": false,\n",
    "      \"action\": \"reach\",\n",
    "      \"consequence\": \"Professor Lin moves her hand toward the pen\",\n",
    "      \"text_describing_the_action\": \"As she reached for her pen\",\n",
    "      \"text_describing_the_consequence\": \"Professor Lin's hand moves toward the pen\",\n",
    "      \"location\": [\"office\", \"desk\"],\n",
    "      \"temporal_order_id\": 6\n",
    "    },\n",
    "    \"appear\": {\n",
    "      \"source\": \"Raj\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"doorway\",\n",
    "      \"target_type\": \"location\",\n",
    "      \"target_is_character\": false,\n",
    "      \"action\": \"appear\",\n",
    "      \"consequence\": \"Raj becomes visible at the doorway\",\n",
    "      \"text_describing_the_action\": \"her colleague Raj appeared at the doorway\",\n",
    "      \"text_describing_the_consequence\": \"Raj is now visible at the doorway\",\n",
    "      \"location\": [\"office\", \"doorway\"],\n",
    "      \"temporal_order_id\": 7\n",
    "    },\n",
    "    \"ask\": {\n",
    "      \"source\": \"Raj\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"Professor Lin\",\n",
    "      \"target_type\": \"person\",\n",
    "      \"target_is_character\": true,\n",
    "      \"action\": \"ask\",\n",
    "      \"consequence\": \"Raj communicates his question\",\n",
    "      \"text_describing_the_action\": \"he asked with a concerned expression\",\n",
    "      \"text_describing_the_consequence\": \"Professor Lin hears Raj's question\",\n",
    "      \"location\": [\"office\", \"doorway\"],\n",
    "      \"temporal_order_id\": 8\n",
    "    },\n",
    "    \"nod\": {\n",
    "      \"source\": \"Professor Lin\",\n",
    "      \"source_type\": \"person\",\n",
    "      \"source_is_character\": true,\n",
    "      \"target\": \"Raj\",\n",
    "      \"target_type\": \"person\",\n",
    "      \"target_is_character\": true,\n",
    "      \"action\": \"nod\",\n",
    "      \"consequence\": \"Professor Lin communicates affirmation\",\n",
    "      \"text_describing_the_action\": \"Professor Lin nodded slightly without looking up\",\n",
    "      \"text_describing_the_consequence\": \"Professor Lin confirms she is working late\",\n",
    "      \"location\": [\"office\", \"desk\"],\n",
    "      \"temporal_order_id\": 9\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "## Required Output Format\n",
    "\n",
    "Always return a complete NarrativeAnalysis object following the provided schema. Ensure the output can be parsed as JSON without errors, do not write python dictionaries and remember properly escaping json strings. Do not include any nested tool_call tags or extra formatting in your response.\n",
    "\n",
    "Remember, your primary task is to extract ALL possible actions from the text, even subtle ones. The `action_names` field must be populated with all action names, and the `actions` dictionary should contain detailed information for each action.\n",
    "remember to respect the output format and \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "class Action(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a concrete physical action between entities in a narrative text.\n",
    "    \"\"\"\n",
    "    # Source entity information\n",
    "    source: str = Field(..., description=\"Name of the entity performing the action\")\n",
    "    source_type: str = Field(..., description=\"Category of the source (person, animal, object, location)\")\n",
    "    source_is_character: bool = Field(..., description=\"Whether the source is a named character\")\n",
    "    \n",
    "    # Target entity information\n",
    "    target: str = Field(..., description=\"Name of the entity receiving the action\")\n",
    "    target_type: str = Field(..., description=\"Category of the target (person, animal, object, location)\")\n",
    "    target_is_character: bool = Field(..., description=\"Whether the target is a named character\")\n",
    "    \n",
    "    # Action details\n",
    "    action: str = Field(..., description=\"The verb or short phrase describing the physical interaction\")\n",
    "    consequence: str = Field(..., description=\"The immediate outcome or result of the action\")\n",
    "    \n",
    "    # Text evidence\n",
    "    text_describing_the_action: str = Field(..., description=\"Text fragment describing the action\")\n",
    "    text_describing_the_consequence: str = Field(..., description=\"Description of the consequence\")\n",
    "    \n",
    "    # Context information\n",
    "    location: List[str] = Field(..., description=\"Hierarchical location from global to local\")\n",
    "    temporal_order_id: int = Field(..., description=\"Sequential identifier for chronological order\")\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"String representation of the Action for human-readable output.\"\"\"\n",
    "        return (\n",
    "            f\"{self.source} ({self.source_type}) {self.action} \"\n",
    "            f\"{self.target} ({self.target_type}) at {self.location[-1]}, \"\n",
    "            f\"resulting in {self.consequence}\"\n",
    "        )\n",
    "\n",
    "class NarrativeAnalysis(BaseModel):\n",
    "    \"\"\"\n",
    "    Simplified analysis of narrative text with entities as strings and actions indexed by name.\n",
    "    \"\"\"\n",
    "    text_id: str = Field(..., description=\"Unique identifier for the analyzed text segment\")\n",
    "    \n",
    "    text_had_no_actions: bool = Field(\n",
    "        default=False,\n",
    "        description=\"Whether the text had no actions to extract\"\n",
    "    )\n",
    "    \n",
    "    text_had_no_actions_explanation: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Explanation of why no actions were found if text_had_no_actions is true\"\n",
    "    )\n",
    "    \n",
    "    # Simple lists of entity names instead of full objects\n",
    "    entity_names: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of all distinct entity names in the text\"\n",
    "    )\n",
    "    \n",
    "    entity_types: Dict[str, str] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"Mapping of entity names to their types (person, animal, object, location)\"\n",
    "    )\n",
    "    \n",
    "    character_entities: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of entity names that are characters in the narrative\"\n",
    "    )\n",
    "    \n",
    "    # Entity mentions mapping\n",
    "    entity_mentions: Dict[str, List[str]] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"Mapping of entity names to their textual mentions\"\n",
    "    )\n",
    "    \n",
    "    # Locations as simple list of paths\n",
    "    locations: List[List[str]] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of hierarchical location paths from global to local\"\n",
    "    )\n",
    "    \n",
    "    # Location descriptions\n",
    "    location_descriptions: Dict[str, str] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"Mapping of location string representations to their descriptions\"\n",
    "    )\n",
    "    action_names: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of all action names in the text\"\n",
    "    )\n",
    "    \n",
    "    # Actions indexed by name\n",
    "    actions: Dict[str, Action] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"Dictionary mapping action names to Action objects\"\n",
    "    )\n",
    "    \n",
    "    def get_action_names(self) -> List[str]:\n",
    "        \"\"\"Return all action names.\"\"\"\n",
    "        return list(self.actions.keys())\n",
    "    \n",
    "    def get_entity_type(self, entity_name: str) -> str:\n",
    "        \"\"\"Get the type of an entity by name.\"\"\"\n",
    "        return self.entity_types.get(entity_name, \"unknown\")\n",
    "    \n",
    "    def is_character(self, entity_name: str) -> bool:\n",
    "        \"\"\"Check if an entity is a character.\"\"\"\n",
    "        return entity_name in self.character_entities\n",
    "    \n",
    "    def get_mentions(self, entity_name: str) -> List[str]:\n",
    "        \"\"\"Get all mentions of an entity.\"\"\"\n",
    "        return self.entity_mentions.get(entity_name, [])\n",
    "    \n",
    "    def get_location_description(self, location_path: List[str]) -> str:\n",
    "        \"\"\"Get the description of a location.\"\"\"\n",
    "        location_key = \"->\".join(location_path)\n",
    "        return self.location_descriptions.get(location_key, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_extractor = StructuredTool.from_pydantic(NarrativeAnalysis)\n",
    "\n",
    "system_prompt = SystemPrompt(name=\"Narrative Action Extraction System\", content=system_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_extractor.json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config_vllm_modal = LLMConfig(client=LLMClient.vllm, model=vllm_model, response_format=ResponseFormat.structured_output,max_tokens=8000)\n",
    "vllm_thread = ChatThread(\n",
    "    system_prompt=system_prompt,\n",
    "    new_message=\"\",\n",
    "    llm_config=llm_config_vllm_modal,\n",
    "    forced_output=action_extractor,\n",
    "    use_schema_instruction=True\n",
    ")\n",
    "\n",
    "def create_vllm_threads(prompts_df:pl.DataFrame):\n",
    "    if isinstance(prompts_df, pl.DataFrame):\n",
    "        if not \"prompt\" in prompts_df.columns:\n",
    "            raise ValueError(\"prompts_df must contain a 'prompt' column\")\n",
    "    else:\n",
    "        raise ValueError(\"prompts_df must be a pl.DataFrame\")\n",
    "    vllm_threads = []\n",
    "    prompts_list = prompts_df[\"prompt\"].to_list()   \n",
    "    for prompt in prompts_list:\n",
    "        vllm_thread = ChatThread(\n",
    "            system_prompt=system_prompt,\n",
    "            new_message=prompt,\n",
    "            llm_config=llm_config_vllm_modal,\n",
    "            forced_output=action_extractor,\n",
    "            use_schema_instruction=False\n",
    "        )\n",
    "        vllm_threads.append(vllm_thread)\n",
    "    return vllm_threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gutenberg_text(text):\n",
    "    \"\"\"\n",
    "    Clean Gutenberg book text by:\n",
    "    - Replacing multiple newlines with a single newline\n",
    "    - Replacing multiple spaces with a single space\n",
    "    - Breaking text into paragraphs based on newlines\n",
    "    \n",
    "    Args:\n",
    "        text (str): The raw Gutenberg book text\n",
    "        \n",
    "    Returns:\n",
    "        list: List of paragraphs\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # First, replace multiple spaces with a single space\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    \n",
    "    # Split text into paragraphs based on newlines\n",
    "    paragraphs = re.split(r'\\n+', text)\n",
    "    \n",
    "    # Remove any empty paragraphs and strip whitespace from each paragraph\n",
    "    paragraphs = [p.strip() for p in paragraphs if p.strip()]\n",
    "    \n",
    "    return paragraphs\n",
    "\n",
    "# Example usage\n",
    "# with open('gutenberg_book.txt', 'r', encoding='utf-8') as file:\n",
    "#     raw_text = file.read()\n",
    "# \n",
    "# paragraphs = clean_gutenberg_text(raw_text)\n",
    "# \n",
    "# # If you want to write the paragraphs back to a file with proper formatting:\n",
    "# with open('cleaned_gutenberg_book.txt', 'w', encoding='utf-8') as file:\n",
    "#     file.wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm_thread.messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels = pl.read_parquet(\"/Users/tommasofurlanello/Documents/Dev/MarketInference/data/gutenberg_en_novels.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_str = novels[\"TEXT\"][777]\n",
    "\n",
    "book_paragraphs = clean_gutenberg_text(book_str)\n",
    "book_paragraphs_str = \"\\n\".join(book_paragraphs)\n",
    "print(len(book_str),len(book_paragraphs_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_paragraphs_df = pl.DataFrame({\"TEXT\": book_paragraphs}).with_columns(pl.col(\"TEXT\").str.len_chars().alias(\"LENGTH\"))\n",
    "book_paragraphs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = {0:[]}\n",
    "paragraphs_lengths = {0:0}\n",
    "paragraph_id = 0\n",
    "max_length = 1000\n",
    "for text,length in book_paragraphs_df.iter_rows():\n",
    "    if paragraphs_lengths[paragraph_id] + length > max_length:\n",
    "        paragraph_id += 1\n",
    "        paragraphs[paragraph_id] = []\n",
    "        paragraphs_lengths[paragraph_id] = 0\n",
    "    paragraphs[paragraph_id].append(text)\n",
    "    paragraphs_lengths[paragraph_id] += length\n",
    "\n",
    "paragraphs_strings = [ \"\\n\".join(paragraphs[i]) for i in paragraphs.keys()]\n",
    "\n",
    "paragraphs_df = pl.DataFrame({\"TEXT\": paragraphs_strings}).with_columns(pl.col(\"TEXT\").str.len_chars().alias(\"LENGTH\"))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_number_context = 0\n",
    "i=10\n",
    "prompts = []\n",
    "chunk_list = []\n",
    "context_list = []\n",
    "for i, chunk in enumerate(paragraphs_df[\"TEXT\"]):\n",
    "    context_chunks_start = max(0, i - chunks_number_context)\n",
    "    non_inclusive_context_str = paragraphs_df[\"TEXT\"][context_chunks_start:i].str.concat(delimiter=\"\\n\")[0]\n",
    "    target_chunk = chunk\n",
    "    prompt = f\"\"\" Utilize the context in the following text {non_inclusive_context_str} to better understand the target text {target_chunk} and extract the actions in the target text.\"\"\"\n",
    "    prompts.append(prompt)\n",
    "    chunk_list.append(target_chunk)\n",
    "    context_list.append(non_inclusive_context_str)\n",
    "\n",
    "prompts_df = pl.DataFrame({\"prompt\": prompts, \"chunk\": chunk_list, \"context\": context_list})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompts = prompts_df#.head(1)\n",
    "example_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = create_vllm_threads(example_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_df[\"prompt\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = await orchestrator.run_parallel_ai_completion(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "validated_outs = []\n",
    "prevalidated_outs = []\n",
    "non_validated_outs = []\n",
    "non_object_outs = []\n",
    "for out in outs:\n",
    "    if out.json_object:\n",
    "        try:\n",
    "            validated_outs.append(NarrativeAnalysis.model_validate(out.json_object.object))\n",
    "            prevalidated_outs.append(out)\n",
    "        except Exception as e:\n",
    "            non_validated_outs.append(out)\n",
    "            print(e)\n",
    "        i=i+1\n",
    "    else:\n",
    "        non_object_outs.append(out)\n",
    "print(i,len(validated_outs),len(non_validated_outs),len(non_object_outs),len(outs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for out in non_validated_outs:\n",
    "    print(out.json_object.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for out in non_object_outs:\n",
    "    if out.raw_output.raw_result[\"choices\"][0][\"finish_reason\"] == \"stop\":\n",
    "        print(out.raw_output.raw_result)\n",
    "    else:\n",
    "        print(\"too long\")\n",
    "        print(out.raw_output.raw_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_outs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_with_actions = [out for out in validated_outs if out.text_had_no_actions == False]\n",
    "len(outs_with_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_frame = pl.DataFrame(outs_with_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_frame.explode(\"locations\").explode(\"locations\")[\"locations\"].value_counts().sort(\"count\",descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_frame[\"actions\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_frame.explode(\"action_names\")[\"action_names\"].value_counts().sort(by=\"count\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_frame.explode(\"entity_names\")[\"entity_names\"].value_counts().sort(by=\"count\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_frame.unnest(\"actions\").shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
